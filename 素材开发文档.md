# 素材 (Materials) 功能开发方案

本方案详细描述如何在 Postiz 工程中接入 `MediaCrawler` 自媒体爬虫服务。

## 1. 总体架构设计

### 1.1 系统组成
*   **Postiz Frontend**: 提供用户界面，发起搜索，通过 SSE (Server-Sent Events) 接收实时进度，并通过轮询作为兜底。
*   **Postiz Backend (NestJS)**: 业务逻辑核心。作为 `MediaCrawler` 的客户端，负责调度爬虫任务、监听状态、获取数据并持久化入库。
*   **MediaCrawler Service**: 外部 Python 服务 (基于 FastAPI)，负责实际的跨平台数据抓取。独立部署，默认端口 8080。

### 1.2 核心流程 (Cache-Aside + Async Crawl)
1.  **发起搜索**: 前端请求 -> 后端 (查库) -(无结果)-> 调用 MediaCrawler 启动爬虫。
2.  **异步监听**: 后端通过 WebSocket 连接 MediaCrawler 监听日志与状态，并通过 SSE 将关键事件推送给前端。
3.  **结果回传**: 爬虫任务完成后，后端调用 MediaCrawler 数据接口读取生成的 JSON 文件，清洗入库，并通知前端更新。

---

## 2. 接口对接方案 (Internal Integration)

由于 `MediaCrawler` 设计为单实例运行 (同一时间只能跑一个任务)，后端需实现**任务锁/队列机制**。

### 2.1 Postiz Materials API (Frontend -> Backend)
*   **搜索/触发任务**: `POST /api/materials/search`
    *   Request:
        ```json
        {
          "platform": "xhs",        // xhs | dy
          "keywords": "关键词",
          "startPage": 1,
          "pageLimit": 3,
          "forceCrawl": false       // true 时忽略缓存直接新起任务
        }
        ```
    *   Response:
        ```json
        {
          "jobId": "job_xxx",
          "state": "queued",
          "cachedResults": [],      // 若命中缓存则返回
          "cachedAt": "2026-01-10T12:00:00Z"
        }
        ```
*   **任务状态**: `GET /api/materials/job-status?jobId=job_xxx`
    *   Response:
        ```json
        {
          "jobId": "job_xxx",
          "state": "running",       // queued | running | login_required | succeeded | failed | canceled | timeout
          "progress": 0.3,
          "message": "正在翻页",
          "error": null
        }
        ```
*   **结果查询**: `GET /api/materials/results?jobId=job_xxx`
*   **事件流**: `GET /api/materials/events?jobId=job_xxx` (SSE)

### 2.2 MediaCrawler API 参考
*   **Base URL**: `http://localhost:8080` (需配置到环境变量 `MEDIACRAWLER_API_URL`)
*   **启动任务**: `POST /api/crawler/start`
    *   Payload:
        ```json
        {
          "platform": "xhs",        // xhs | dy
          "crawler_type": "search", // search | detail
          "keywords": "关键词",
          "client_job_id": "job_xxx", // 后端传入 jobId，推荐启用
          "login_type": "qrcode",   // qrcode | cookie
          "save_option": "json",    // 强制使用 json 以便后端读取
          "start_page": 1
        }
        ```
    *   Response:
        ```json
        {
          "client_job_id": "job_xxx",
          "status": "accepted",
          "accepted_at": "2026-01-10T12:00:00Z"
        }
        ```
*   **查询状态**: `GET /api/crawler/status` (返回 `idle`, `running` 等)
    *   Response:
        ```json
        {
          "state": "running",
          "client_job_id": "job_xxx",
          "started_at": "2026-01-10T12:00:00Z",
          "message": "正在抓取"
        }
        ```
*   **停止任务**: `POST /api/crawler/stop`
    *   Response:
        ```json
        {
          "status": "stopped"
        }
        ```
*   **状态流**: `WS /api/ws/status` (每秒推送一次状态)
    *   Message:
        ```json
        {
          "type": "status",
          "client_job_id": "job_xxx",
          "state": "running",
          "progress": 0.3,
          "message": "正在翻页"
        }
        ```
*   **日志流**: `WS /api/ws/logs` (实时日志)
    *   Message:
        ```json
        {
          "type": "log",
          "client_job_id": "job_xxx",
          "level": "info",
          "message": "开始采集",
          "timestamp": "2026-01-10T12:00:05Z"
        }
        ```
*   **获取数据列表**: `GET /api/data/files?platform=xhs&file_type=json` (按时间倒序)
    *   Response:
        ```json
        [
          {
            "path": "xhs/20260110_120300.json",
            "client_job_id": "job_xxx",
            "created_at": "2026-01-10T12:03:00Z"
          }
        ]
        ```
*   **读取数据**: `GET /api/data/files/{file_path}`
*   **约束与对策 (Constraints & Solutions)**:
    *   **Task ID**: 经验证，MediaCrawler `/start` 接口**不返回** `task_id`，后续流程不得依赖该字段。
    *   **可选字段**: 若 `/status` 或 WS 日志携带 `task_id`，仅用于排障，不作为关联依据。
    *   **唯一标识**: 后端必须在 `materialQueue` 中生成 UUID 格式的 `jobId`，作为全链路唯一标识。
    *   **日志关联**: 单实例模式下，WS/SSE 日志默认归属于当前 `running` 的 Job，后端在转发 SSE 时强制注入 `jobId`。
    *   **结果关联**: 优先使用 `client_job_id` 精确匹配；若暂不支持，则使用 `startedAt` 时间窗口 + 未消费文件作为兜底。
    *   **Stop接口**: 经验证已支持 `POST /api/crawler/stop`，可用于僵尸任务清理。

### 2.2.1 MediaCrawler 最小增强方案 (推荐采用)
为确保结果关联从“猜测”变为“确定”，建议在 MediaCrawler 侧做以下最小增强：
*   **/start 支持 client_job_id**: 后端传入 `jobId`。
*   **输出带 client_job_id**: 输出文件名或元数据中必须包含 `client_job_id`。
*   **WS 携带 client_job_id**: `status/logs` 推送时附带 `client_job_id`。
*   **/data/files 返回 client_job_id**: 列表中提供 `client_job_id` 便于精确匹配。
*   **兼容策略**: 若暂不支持，后端继续使用 `startedAt + 未消费文件` 的兜底关联。

#### 2.2.1.1 变更清单 (接口/字段)
*   **POST /api/crawler/start**: 新增可选字段 `client_job_id`，并回显 `client_job_id`。
*   **GET /api/crawler/status**: 响应新增 `client_job_id` (若当前任务存在)。
*   **WS /api/ws/status|logs**: 消息体新增 `client_job_id`。
*   **GET /api/data/files**: 列表项新增 `client_job_id` 或 `job_id` (推荐 `client_job_id`)。

#### 2.2.1.2 兼容测试项
*   传入 `client_job_id` 时，`/start` 响应与 WS 消息均包含该字段。
*   任务完成后，`/data/files` 返回的文件项携带对应 `client_job_id`。
*   未传 `client_job_id` 时，服务保持兼容，不影响现有流程。
*   `/stop` 对当前任务生效，且后续状态变为 `idle`。

### 2.3 后端服务设计 (`ExternalMaterialProvider`)

#### A. 任务调度与队列 (基于 BullMQ)
*   **选型**: 推荐使用 `BullMQ` (基于 Redis) 管理任务队列，利用其内置的 Dead Letter Queue (DLQ)、指数退避重试 (Exponential Backoff) 与 Stalled Job Detection (卡死检测) 能力。
*   **依赖**: 复用项目已有 Redis (`REDIS_URL`)。
*   **Job 数据结构**:
    *   `id`: 任务ID (UUID)
    *   `data`: `{ orgId, platform, keywords, queryHash, options }`
*   **DB 记录字段**: `startedAt`, `finishedAt`, `resultPath` 用于结果关联与追溯。
*   **Start 流程**:
    1.  **查重**: 计算 `queryHash` (md5 of params)。检查 Redis 中是否有 `completed` 且未过期的 Job。若有，直接返回缓存。
    2.  **入队**: `materialQueue.add('crawl', data, { jobId: uuid })`。
    3.  **并发控制**: 设置 Worker `concurrency: 1` (确保单实例访问 MediaCrawler)。
    4.  **开始时间**: 调用 `/start` 前记录 `startedAt`，用于结果关联。
*   **Progress (Bridge)**:
    1.  Worker 处理任务时，通过 `job.updateProgress()` 更新进度。
    2.  建立到 MediaCrawler 的 WS 连接，将收到的消息通过 SSE 转发给前端。

#### B. 任务状态机与事件映射
1.  **状态流转**:
    *   `queued` (入队) -> `running` (执行中) -> `succeeded` (成功)
    *   `running` -> `login_required` (需登录) -> `running`
    *   `running` -> `failed` (失败) / `timeout` (超时) / `canceled` (取消)
    *   状态流转示意 (ASCII):
        ```
        queued -> running -> succeeded
                       -> login_required -> running
                       -> failed
                       -> timeout
                       -> canceled
        ```
2.  **SSE 事件**:
    *   `status`: `{ state, progress, message }`
    *   `log`: `{ level, message, timestamp }`
    *   `login_qrcode`: `{ base64_image, expire_at }`
    *   `result`: `{ count, first_item_preview }`
    *   `error`: `{ code, reason, retryable }`

#### C. 数据回收 (Data Reclamation)
*   当监听到状态从 `running` 变为 `idle` 且无错误时：
    1.  调用 `GET /api/data/files?platform={platform}&file_type=json`。
    2.  若列表包含 `client_job_id`，按 `client_job_id == jobId` 精确匹配。
    3.  若未支持 `client_job_id`，以 `startedAt` 为起点筛选 `created_at >= startedAt` 的文件，且未被任何 Job 关联过。
    4.  若无候选文件，标记为 `failed` (reason: "No output file") 并推送 `SSE: error`。
    5.  若存在多个候选，按 `created_at` 取最新，并记录告警日志。
    6.  调用 `GET /api/data/files/{path}` 获取内容。
    7.  解析 JSON，保存原始 payload，映射到 `Material` 实体并 `upsert` 入库。
    8.  在 DB 记录 `jobId` 与 `resultPath` 的绑定，避免二次消费。
    9.  推送 `SSE: result` 事件，携带新数据或结果摘要。

#### D. 幂等与去重
*   `Material` 以 `(orgId, platform, externalId)` 建唯一索引。
*   相同 `queryHash` 的短期重复请求，复用最近成功结果 (TTL)。

#### E. 异常恢复与僵尸任务处理 (Zombie Job Handling)
*   **问题**: 后端服务重启或 Crash 会导致内存中的 WS 连接断开，但 Job 状态仍为 `running`。
*   **对策**:
    1.  **BullMQ Stalled Check**: BullMQ 会自动检测失去心跳的 Job 并使其重新入队或标记失败。
    2.  **Start Cleanup 策略**: 后端启动时，扫描数据库中所有 `state='running'` 的任务。
        *   若 `updatedAt` 超过阈值 (如 5min)，标记为 `failed` (reason: "System Restart")。
        *   调用 MediaCrawler `POST /api/crawler/stop` 确保外部进程不残留。

#### F. 登录鉴权处理 (Login Authentication)
为确保爬虫服务可用，需处理“未登录”或“Cookie失效”的情况。参考日历功能的“Add Channel”交互。

1.  **检测登录状态**:
    *   后端通过 WS 日志或状态检测到 `LOGIN_REQUIRED` 或 `COOKIE_EXPIRED` 错误。
    *   或者用户在前端点击“添加账号/登录”按钮。

2.  **二维码获取流程**:
    *   后端调用 MediaCrawler 启动登录模式 (如 `crawler_type: "login"`，需确认 MediaCrawler 支持或扩展该功能，若不支持则需通过 `headless: false` 配合后端截图/OCR提取二维码，或升级 MediaCrawler 以支持二维码流输出)。
    *   **理想方案**: MediaCrawler 通过 WS 推送 `QRCODE_GENERATED` 事件及 Base64 图片。

3.  **前端交互**:
    *   后端通过 SSE 推送 `SHOW_LOGIN_MODAL` 事件，携带 `platform` 信息。
    *   前端收到事件后，弹出 **二维码登录模态框** (参考 `AddProviderComponent`)。
    *   模态框内显示二维码图片，并轮询登录状态。

4.  **扫码成功**:
    *   MediaCrawler 检测到登录成功，推送 `LOGIN_SUCCESS`。
    *   后端通知前端关闭模态框，并自动重试之前的搜索任务。

---

## 3. 前端开发方案 (Frontend)

### 3.1 页面交互
*   **搜索区**: 平台选择(抖音/小红书) + 关键词输入 + “搜索”按钮。
*   **展示区**:
    *   **初始状态**: 显示空或历史记录。
    *   **Database Results**: 点击搜索，立即显示数据库中已有的缓存结果。
    *   **Crawler Status**: 如果触发了爬虫，显示一个进度条或终端风格的日志窗口。
    *   **New Results**: 爬虫完成后，自动刷新网格，高亮显示新获取的素材。

### 3.2 登录弹窗 (QR Code Modal)
*   **参考组件**: `apps/frontend/src/components/launches/add.provider.component.tsx` 中的 `AddProviderComponent` 和 `ApiModal`。
*   **新组件**: `MaterialsLoginModal`
    *   **UI**: 包含标题 "Login to {Platform}"，居中的二维码区域，以及状态提示 ("请使用 {App} 扫码登录")。
    *   **逻辑**: 接收 Base64 二维码图片，或显示 Loading 状态直到接收到二维码。

### 3.3 轮询与 SSE (Polling & SSE)
为了保证鲁棒性，采用双重机制：

1.  **SSE (Server-Sent Events)**:
    *   建立连接: `new EventSource('/api/materials/events?jobId=job_xxx')`。
    *   监听事件: `log` (日志), `status` (状态变更), `result` (最终数据), `login_qrcode` (登录二维码), `error` (错误)。
    *   Payload 示例:
        ```json
        {
          "jobId": "job_xxx",
          "state": "running",
          "progress": 0.4,
          "message": "正在翻页"
        }
        ```
    *   **优势**: 实时性高，能展示详细爬取过程（"正在登录...", "正在翻页..."）。

2.  **轮询 (Polling) (兜底方案)**:
    *   使用 `useSWR` 或 `setInterval`，每 3-5 秒请求一次 `/api/materials/job-status?jobId=job_xxx`。
    *   **用途**: 防止 SSE 连接断开导致状态卡死；检查后端是否意外重启。

---

## 4. 实施细节与配置

### 4.1 环境变量
在 `.env` 中添加：
```env
MEDIACRAWLER_API_URL=http://localhost:8080
MEDIACRAWLER_API_KEY=changeme
ENABLE_CRAWLER_LOGS_FORWARDING=true
MATERIALS_JOB_TTL_MINUTES=30
MATERIALS_MAX_RUNTIME_SECONDS=180
MATERIALS_POLL_INTERVAL_MS=3000
MATERIALS_QUEUE_NAME=materials
MATERIALS_JOB_ATTEMPTS=3               # [Critical] 必须与代码中 BullMQ Job 配置保持一致
MATERIALS_JOB_BACKOFF_MS=5000          # [Critical] 指数退避基数 (ms)
MATERIALS_JOB_STALLED_INTERVAL_MS=30000 # [Critical] 对应 BullMQ stalledInterval (ms)
MATERIALS_JOB_MAX_STALLED_COUNT=2      # [Critical] 对应 BullMQ maxStalledCount
# 兼容说明: 若代码仍使用 MATERIALS_JOB_STALLED_THRESHOLD, 其含义必须与 stalledInterval 一致
```

### 4.2 错误处理
*   **MediaCrawler 未启动**: 后端捕获连接拒绝错误，提示用户“爬虫服务未就绪”。
*   **登录失败/二维码失效**: 通过 WS 日志捕获关键词，通过 SSE 提示用户“需要人工介入扫码”。(注：MediaCrawler 需要在服务器端扫码，这对纯 Web 端用户有挑战，建议 MVP 阶段预先配置好 Cookie 或在服务器终端扫码)。
*   **超时**: 后端设置最大任务时间（如 3分钟），超时强制标记失败并释放锁。
*   **重试**: 对网络类错误增加有限重试与退避，避免无限重试。
*   **取消**: 前端可提供取消入口，后端标记 `canceled` 并清理锁与连接。

### 4.3 安全与权限
*   Postiz <-> MediaCrawler 使用 API Key 或 mTLS 认证。
*   `MEDIACRAWLER_API_KEY` 默认通过 `Authorization: Bearer <key>` 传递。
*   对 `file_path` 做严格白名单校验，禁止目录穿越。
*   爬虫登录 Cookie/凭证需加密存储，并具备最小化权限与过期策略。
*   增加访问频率限制与审计日志 (包含 orgId、queryHash、jobId)。

### 4.4 运维与监控
*   增加健康检查：MediaCrawler `/health`，后端可定期探活。
*   监控指标：任务耗时、成功率、失败原因、队列长度。
*   资源约束：爬虫 CPU/内存限额与超时阈值。
*   任务清理：定期清理过期 Job 与临时文件，防止磁盘膨胀。

### 4.5 死信队列与告警策略 (DLQ Policy)
*   **触发条件**: 任务重试次数耗尽 (`attempts >= 3`) 后进入 DLQ。
*   **保留策略**: DLQ 任务保留 **7天** 以供排查，之后自动过期。
*   **处理流程**:
    1.  **自动告警**: 监控系统基于 BullMQ `failed` 事件或队列指标(失败计数/速率)触发。
    2.  **人工干预**: 运维/开发通过 API (`POST /api/materials/jobs/{id}/retry`) 或 Redis 界面查看 `stacktrace`。
    3.  **重放/丢弃**: 修复 Bug 或网络问题后手动重放；若是无效输入则丢弃。

### 4.6 性能/限制优化
*   **SSE 连接限制**: 浏览器 (HTTP/1.1) 对同一域名限制 ~6 个并发连接。若用户同时开多个 Tab 可能会阻塞。
    *   **建议**: 使用 HTTP/2 (Nginx/ALB 支持) 复用连接，或通过 SharedWorker 共享连接。
    *   **前端约束**: 单页面仅保持 1 个 EventSource 实例。
    *   **MVP**: 页面卸载 (`beforeunload`) 时显式关闭 EventSource。

### 4.7 数据映射 (Material Schema)
MediaCrawler 返回的 JSON 结构通常包含：
```json
{
  "id": "帖子ID",
  "title": "标题",
  "desc": "描述",
  "images": ["url1", "url2"],
  "video": {"url": "video_url"},
  "nickname": "作者名",
  "user_id": "作者ID"
}
```
需映射到 Prisma `Material` 模型字段：
*   `externalId` <- `id`
*   `contentUrl` <- `video.url` (优先) 或 `images[0]`
*   `coverUrl` <- `images[0]`
*   `authorName` <- `nickname`
*   `authorId` <- `user_id`
*   `platform` <- `platform`
*   `orgId` <- 当前组织
*   `rawPayload` <- 原始 JSON (便于审计与回溯)
*   **索引建议**: `(orgId, platform, externalId)` 唯一索引；`queryHash` 普通索引用于缓存命中。

---

## 5. 验收与测试
*   **契约测试**: Mock MediaCrawler，校验 `jobId` 注入与事件 payload。
*   **集成测试**: 测试任务排队、登录要求、超时与取消流程。
*   **E2E**: 前端触发搜索 -> SSE 进度 -> 结果落库 -> UI 展示。
*   **负载测试**: 多用户并发请求时，队列与锁行为符合预期。
*   **可观测性**: 日志与指标覆盖关键路径，能定位失败原因。

---

## 6. 推荐落地方案 (Best Plan)
1.  **先建模型与队列**: 新增 Job 表 + BullMQ 队列，Worker 并发固定为 1。
2.  **以 `jobId` 贯穿**: 前端请求返回 `jobId`；后端 SSE/日志转发强制注入 `jobId`。
3.  **优先精确关联**: 若 MediaCrawler 支持 `client_job_id`，按其匹配输出；否则使用 `startedAt` 时间窗口兜底。
4.  **容错与恢复**: 启动清理 + `/stop` 清理残留 + Stalled/DLQ 处理。
5.  **配置一致性**: `ATTEMPTS/BACKOFF/STALLED_*` 作为 [Critical] 配置，通过 CI 检查与代码常量一致。

---

## 7. 后端实现清单 (Phase 1)
*   **MediaCrawler 客户端**: `/start` 透传 `client_job_id`，`/data/files` 解析 `client_job_id`。
*   **结果回收逻辑**: 优先按 `client_job_id` 精确匹配，否则使用 `startedAt + 未消费文件` 兜底。
*   **DB 绑定**: 保存 `jobId` 与 `resultPath`，防止重复消费。
*   **启动清理**: 重启时对 `running` 任务执行 `/stop` 与状态修正。
